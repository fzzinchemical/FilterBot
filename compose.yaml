services:
  ollama:
    image: ollama/ollama:rocm
    networks:
      - my_network
    volumes:
      - ${OLLAMA_CONFIG_PATH}:/root/.ollama # shared ollama configuration
      - /mnt/4TB_NVME/Ollama/Models:/root/.ollama/models # shared ollama models
    devices:
      - /dev/kfd:/dev/kfd
      - /dev/dri:/dev/dri
    command: ["serve"] # Add the command to start ollama
    # ports:
    #   - "11000:11434" # Open port for debugging and testing in case of issues
    privileged: true
  
  pyllama_summary:
    build: .
    networks:
      - my_network
    depends_on:
      - ollama
    volumes:
      - .:/app
      - ${INPUT_FOLDER_PATH}:/shared_data
      - ${OUTPUT_FOLDER_PATH}:/shared_data_out
    environment:
      - OLLAMA_API_URL=${OLLAMA_API_URL}
      - OLLAMA_MODEL=${OLLAMA_MODEL}
      - OLLAMA_CHUNK_SIZE=${OLLAMA_CHUNK_SIZE}
      - CHUNKING_CYCLES=${CHUNKING_CYCLES}
    command: ["python", "-u", "main.py", "/shared_data/", "/shared_data_out/"]
    privileged: true

networks:
  my_network:
    driver: bridge
